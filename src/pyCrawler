import json
import sys
import datefinder
from selenium import webdriver

chromeDriverFile = ""
crawlingDate = ""

def OpenTargetUrl(subject, url):

    option = webdriver.ChromeOptions()
    option.headless = True;
    option.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36")
    driver = webdriver.Chrome(chromeDriverFile, options=option)

    driver.get(url)
    driver.implicitly_wait(3)

    contents_list = driver.find_element_by_xpath('//*[@id="aNews_List"]/ul')
    contents = contents_list.find_elements_by_tag_name('li')

    for content in contents:
        newsDate = list(datefinder.find_dates(str(content.find_element_by_xpath('//a/div').text)))
        if newsDate == crawlingDate:
            content.click()
            


# 크롤링 타겟 설정
def MakeRequest(targetCategoriesFile, targetURL):
    with open(targetCategoriesFile, 'r') as target:
        categories = json.load(target)

    for categories in categories["Categories"]:
        if categories["target"] == "enabled":
            url = targetURL + str(categories["id"])
            subject = categories["subject"]

            print("url" + url)
            print("subject" + subject)

            OpenTargetUrl(subject, url)

# main function
if __name__ == "__main__":

    # Program argument setting
    #   argument :: crawling - date


    # 환경 설정 파일 로딩
    with open('../config/config.json', 'r') as configFile:
        config = json.load(configFile)

    chromeDriverFile = config["LOCAL"]["ChromeDriverPath"] + "/" + config["DEFAULT"]["ChromeDriver"]

    targetURL = config["DEFAULT"]["TargetUrl"]
    targetCategoriesFile = config["LOCAL"]["ResourcePath"] + "/" + config["DEFAULT"]["ResourceFile"]

    MakeRequest(targetCategoriesFile, targetURL)
    
    
    
    